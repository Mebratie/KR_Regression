{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab98c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3):\n",
      "(0.9911737093494568, 1.523416263304777, 0.7851207660494588)\n",
      "(1.9556349709221001, 0.6879000697274102, 0.6561756980541822)\n",
      "(0.6002620400313977, 0.08252326988293676, 2.6169254287893584)\n",
      "(1.7497033906553365, 0.24368740511830045, 1.3063199429300556)\n",
      "(1.2571418904872391, 0.17113748176273852, 1.8714313664537152)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import sympy as sp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sympy import symbols, Function, diff\n",
    "output_directory = r'../../../Data/3D_Lotka_Volterra/3D_Lotka_T5_N10'\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(0.05, 2)\n",
    "    x2 = random.uniform(0.05, 2)\n",
    "    x3 = random.uniform(0.05, 2)\n",
    "    return x1, x2, x3\n",
    "def calculate_c(x1, x2, x3):\n",
    "    c = x1 + x2 + x3\n",
    "    return c\n",
    "def generate_random_values_based_on_c(c):\n",
    "    min_val = 0.05\n",
    "    max_val = 2\n",
    "    x1 = random.uniform(min_val, min(max_val, c - min_val * 2))\n",
    "    x2 = random.uniform(min_val, min(max_val, c - x1 - min_val))\n",
    "    x3 = c - x1 - x2\n",
    "    return x1, x2, x3\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0: \n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3 = y\n",
    "        f = np.array([x1 * (x2 - x3), x2 * (x3 - x1), x3 * (x1 - x2)])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    num_trajectories = 5\n",
    "    t = np.linspace(0, 100, 10) # 10 data points per trajectory\n",
    "    all_trajectory_data = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3):\")\n",
    "    for i, initial_condition in enumerate(initial_conditions):\n",
    "        print(f\"({initial_condition[0]}, {initial_condition[1]}, {initial_condition[2]})\")\n",
    "        sol = odeint(normalized_system, initial_condition, t)\n",
    "        all_trajectory_data.append(sol)\n",
    "    num_variables = 3 # Adjust number of variables that we need for the regression accordingly\n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')\n",
    "    with open('50.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, data in enumerate(all_trajectory_data):\n",
    "            for j in range(len(t)):\n",
    "                row = data[j].tolist() + [r + 1]\n",
    "                writer.writerow(row) \n",
    "    output_directory1 = r'../../../results/3D_Lotka_Volterra/3D_Lotka_T5_N10'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, sol in enumerate(all_trajectory_data):\n",
    "        for j in range(sol.shape[1]):\n",
    "            plt.plot(t, sol[:, j])\n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None\n",
    "    with open(r'../../../Data/3D_Lotka_Volterra/3D_Lotka_T5_N10/trainingp_data50.csv', 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)\n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)\n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)\n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i+1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3 = generate_random_values()\n",
    "    c = calculate_c(x1, x2, x3)\n",
    "    initial_conditions = [generate_random_values_based_on_c(c) for _ in range(5)]\n",
    "    generate_data(initial_conditions)\n",
    "    data = np.genfromtxt('50.csv', delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72edabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "output_directory = r'../../../Data/3D_Lotka_Volterra/3D_Lotka_T5_N10'\n",
    "output_director = r'../../../System/3D_Lotka_Volterra/3D_Lotka_T5_N10'\n",
    "output_directoryk = r'../../../Data/3D_Lotka_Volterra/3D_Lotka_T5_N10/k_fold'\n",
    "m = 5\n",
    "m1 = 5  \n",
    "m2 = 6 \n",
    "tm = 10\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(0.05, 2)\n",
    "    x2 = random.uniform(0.05, 2)\n",
    "    x3 = random.uniform(0.05, 2)\n",
    "    return x1, x2, x3\n",
    "def calculate_c(x1, x2, x3):\n",
    "    c = x1 + x2 + x3\n",
    "    return c\n",
    "def generate_random_values_based_on_c(c):\n",
    "    min_val = 0.05\n",
    "    max_val = 2\n",
    "    x1 = random.uniform(min_val, min(max_val, c - min_val * 2))\n",
    "    x2 = random.uniform(min_val, min(max_val, c - x1 - min_val))\n",
    "    x3 = c - x1 - x2\n",
    "    return x1, x2, x3\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0: \n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3 = y\n",
    "        f = np.array([x1 * (x2 - x3), x2 * (x3 - x1), x3 * (x1 - x2)])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    t1 = np.linspace(0, 10, tm)  # forward\n",
    "    t2 = np.linspace(0, 10, tm)  # backward\n",
    "    forward_trajectories = []\n",
    "    backward_trajectories = []\n",
    "    print(\"Initial data (x1, x2, x3):\")\n",
    "    for initial_condition in initial_conditions:\n",
    "        # Print the initial conditions with the first five digits\n",
    "        formatted_initial_condition = tuple(f\"{value:.5f}\" for value in initial_condition)\n",
    "        print(formatted_initial_condition) \n",
    "        forward_trajectory = odeint(normalized_system, initial_condition, t1)\n",
    "        backward_trajectory = odeint(normalized_system, initial_condition, -t2)\n",
    "        forward_trajectories.append(forward_trajectory[:m1])\n",
    "        backward_trajectories.append(backward_trajectory[:m2])\n",
    "    return forward_trajectories, backward_trajectories, t1[:m1], t2[:m2]\n",
    "def save_data(forward_trajectories, backward_trajectories, t1, t2):\n",
    "    num_variables = 3 \n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')    \n",
    "    with open(os.path.join(output_director, '50.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, (forward_data, backward_data) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "            for j in range(len(t1)):\n",
    "                forward_row = [f\"{value:.5f}\" for value in forward_data[j]] + [r + 1]\n",
    "                writer.writerow(forward_row)\n",
    "            for j in range(1, len(t2)):  \n",
    "                backward_row = [f\"{value:.3f}\" for value in backward_data[j]] + [r + 1]\n",
    "                writer.writerow(backward_row)\n",
    "    output_directory1 = r'../../../results/3D_Lotka_Volterra/3D_Lotka_T5_N10'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (forward_sol, backward_sol) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "        for j in range(forward_sol.shape[1]):\n",
    "            plt.plot(t1, forward_sol[:, j])\n",
    "            plt.plot(-t2, backward_sol[:, j])  \n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)\n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)\n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)\n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i + 1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "def k_fold_csv(input_directory, file_indices, output_index, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)    \n",
    "    output_file = os.path.join(output_directory, f'a50{output_index}.csv')\n",
    "    input_files = [f'B50{i}.csv' for i in file_indices]\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for file in input_files:\n",
    "        file_path = os.path.join(input_directory, file)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist.\")   \n",
    "    combined_df = combined_df.sort_values(by='trajectory')\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3 = generate_random_values()\n",
    "    c = calculate_c(x1, x2, x3)\n",
    "    initial_conditions = [generate_random_values_based_on_c(c) for _ in range(m)]\n",
    "    forward_trajectories, backward_trajectories, t1, t2 = generate_data(initial_conditions)\n",
    "    save_data(forward_trajectories, backward_trajectories, t1, t2)    \n",
    "    data = np.genfromtxt(os.path.join(output_director, '50.csv'), delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([f\"{row[col]:.5f}\" if col != 'trajectory' else int(row[col]) for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([f\"{row[col]:.5f}\" if col != 'trajectory' else int(row[col]) for col in column_names])\n",
    "    split_data()\n",
    "    file_indices_list = [\n",
    "        [1, 2, 3, 4],\n",
    "        [1, 2, 3, 5],\n",
    "        [1, 2, 4, 5],\n",
    "        [1, 3, 4, 5],\n",
    "        [2, 3, 4, 5]\n",
    "    ]\n",
    "    for i, file_indices in enumerate(file_indices_list, start=1):\n",
    "        k_fold_csv(output_directory, file_indices, i, output_directoryk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d0b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
