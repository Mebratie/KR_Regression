{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ebf7a2",
   "metadata": {},
   "source": [
    "  \\begin{equation}\\label{eq:LVln}\n",
    "    \\begin{gathered}\n",
    "      \\dot{x}_{1}=x_{1}(3-x_{2}-x_{3}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{2}=x_{2}(x_{1}-x_{3})\\,,\\\\\n",
    "      \\dot{x}_{3}=x_{3}(-1+x_{1}+x_{2}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{4}=x_{4}(-2+x_{1}+x_{3})\\,,\n",
    "    \\end{gathered}\n",
    "  \\end{equation}\n",
    "  where $x_5=\\ln(x_1), x_6=\\ln(x_2), x_7=\\ln(x_3), x_8=\\ln(x_4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc289015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import sympy as sp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sympy import symbols, Function, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcef1e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3, x4):\n",
      "(2.4360438789453474, 1.7513145798373926, 2.7607222914244196, 2.3354744373038336)\n",
      "(0.8506439177035028, 0.9134769261888882, 0.3590223629625286, 0.7185799119599543)\n",
      "(3.888763777664364, 3.2651381170954683, 0.33044355446955687, 0.7145347825518236)\n",
      "(0.7759923635288791, 2.456280675181136, 1.434018064029456, 0.9872568338055565)\n",
      "(2.6144713501508576, 2.9167886257224658, 3.3668736039302662, 3.7118317669983787)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import sympy as sp\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sympy import symbols, Function, diff\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N10'\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "# def calculate_c(x1, x2, x3):\n",
    "#     c = x1 + x2 + x3\n",
    "#     return c\n",
    "def generate_random_values_based_on_c():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0: \n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3, x4 = y\n",
    "        f = np.array([x1 * (3 - x2 - x3 - x4), x2 * (x1 - x3), x3 * (-1 + x1 + x2 - x4), x4 * (-2 + x1 + x3)])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    def compute_energy(x1, x2, x3, x4):\n",
    "        return 0.5 * (x3**2 + x4**2) + 0.5 * (x1**2 + x2**2) + x1**2 * x2 - (1/3) * x2**3\n",
    "    num_trajectories = 5\n",
    "    t = np.linspace(0, 100, 10) # 10 data points per trajectory\n",
    "    all_trajectory_data = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3, x4):\")\n",
    "    for i, initial_condition in enumerate(initial_conditions):\n",
    "        print(f\"({initial_condition[0]}, {initial_condition[1]}, {initial_condition[2]}, {initial_condition[3]})\")\n",
    "        sol = odeint(normalized_system, initial_condition, t)\n",
    "        all_trajectory_data.append(sol)\n",
    "    num_variables = 8 # Adjust number of variables that we need for the regression accordingly\n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')\n",
    "    with open('50.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, data in enumerate(all_trajectory_data):\n",
    "            for j in range(len(t)):\n",
    "                x1 = data[j, 0]\n",
    "                x2 = data[j, 1]\n",
    "                x3 = data[j, 2]\n",
    "                x4 = data[j, 3]\n",
    "                writer.writerow([x1, x2, x3, x4, math.log(x1), math.log(x2), math.log(x3), math.log(x4), r+1]) \n",
    "    output_directory1 = r'../../../results/4D_Lotka_Volterra/4D_Lotka_T5_N10'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, sol in enumerate(all_trajectory_data):\n",
    "        for j in range(sol.shape[1]):\n",
    "            plt.plot(t, sol[:, j])\n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None\n",
    "    with open('../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N10/trainingp_data50.csv', 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)\n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)\n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)\n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i+1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3, x4 = generate_random_values()\n",
    "    initial_conditions = [generate_random_values_based_on_c() for _ in range(5)]  # number of trajectories\n",
    "    generate_data(initial_conditions)\n",
    "    data = np.genfromtxt('50.csv', delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = r'../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N10'\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N10/Traj_data'\n",
    "df14 = pd.read_csv(os.path.join(input_directory, '50.csv')) # 50.csv, saved names of the data\n",
    "Br = pd.read_csv('../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N10/50.csv')\n",
    "tr = Br.groupby('trajectory').size()\n",
    "re1 = int(round(tr.mean()))\n",
    "rows_per_file = re1 \n",
    "num_files = len(df14) // rows_per_file\n",
    "data_chunks = [df14.iloc[i * rows_per_file:(i + 1) * rows_per_file].iloc[:, :-1] for i in range(num_files)]\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "for i, chunk in enumerate(data_chunks):\n",
    "    chunk.to_csv(os.path.join(output_directory, f'tr_{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead92dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
