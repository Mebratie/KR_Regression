{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b9f918",
   "metadata": {},
   "source": [
    "  \\begin{equation}\\label{eq:LVln}\n",
    "    \\begin{gathered}\n",
    "      \\dot{x}_{1}=x_{1}(3-x_{2}-x_{3}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{2}=x_{2}(x_{1}-x_{3})\\,,\\\\\n",
    "      \\dot{x}_{3}=x_{3}(-1+x_{1}+x_{2}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{4}=x_{4}(-2+x_{1}+x_{3})\\,,\n",
    "    \\end{gathered}\n",
    "  \\end{equation}\n",
    "  $x_5=\\ln(x_1), x_6=\\ln(x_2), x_7=\\ln(x_3), x_8=\\ln(x_4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c57e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3, x4, x5):\n",
      "(3.555337112359733, 3.9803796920740573, 2.2241306837332036, 3.1403017880924713)\n",
      "(0.7943451134573567, 3.6995151678020997, 1.3069789806905443, 2.758910162179938)\n",
      "(2.2396473204525957, 3.234462604376832, 1.8714759533130418, 3.1605324358170828)\n",
      "(1.4465833285267324, 0.49723819638753664, 3.3629926892580584, 2.2628798178727365)\n",
      "(2.7574879170827487, 3.6631536093300108, 0.474335175105511, 3.939815692535714)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "output_director = r'../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "output_directoryk = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N40/k_fold'\n",
    "m = 5  # number of trajectory\n",
    "m1 = 20  # data point per trajectory divided by 2, which means the total data point is m*(2m1)=40\n",
    "m2 = 21\n",
    "tm = 30\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "def generate_random_values_based_on_c():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0:\n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3, x4 = y\n",
    "        f = np.array([x1 * (3 - x2 - x3 - x4), x2 * (x1 - x3), x3 * (-1 + x1 + x2 - x4), x4 * (-2 + x1 + x3)])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    t1 = np.linspace(0, 10, tm) # forward\n",
    "    t2 = np.linspace(0, 10, tm) # backward\n",
    "    forward_trajectories = []\n",
    "    backward_trajectories = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3, x4, x5):\")\n",
    "    for initial_condition in initial_conditions:\n",
    "        print(initial_condition) \n",
    "        forward_trajectory = odeint(normalized_system, initial_condition, t1)\n",
    "        backward_trajectory = odeint(normalized_system, initial_condition, -t2)\n",
    "        forward_trajectories.append(forward_trajectory[:m1])\n",
    "        backward_trajectories.append(backward_trajectory[:m2])\n",
    "    return forward_trajectories, backward_trajectories, t1[:m1], t2[:m2]\n",
    "def save_data(forward_trajectories, backward_trajectories, t1, t2):\n",
    "    num_variables = 8 \n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')    \n",
    "    with open(os.path.join(output_director, '50.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, (forward_data, backward_data) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "            for j in range(len(t1)):\n",
    "                forward_row = forward_data[j].tolist()\n",
    "                forward_row += [math.log(max(x, 1e-10)) for x in forward_row[:num_variables - 1]]\n",
    "                forward_row += [r + 1]\n",
    "                writer.writerow(forward_row)\n",
    "            for j in range(1, len(t2)):  # Exclude initial conditions for backward trajectory\n",
    "                backward_row = backward_data[j].tolist()\n",
    "                backward_row += [math.log(max(x, 1e-10)) for x in backward_row[:num_variables - 1]]\n",
    "                backward_row += [r + 1]\n",
    "                writer.writerow(backward_row)  \n",
    "    output_directory1 = r'../../../results/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (forward_sol, backward_sol) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "        for j in range(forward_sol.shape[1]):\n",
    "            plt.plot(t1, forward_sol[:, j])\n",
    "            plt.plot(-t2, backward_sol[:, j])  # Exclude initial conditions for backward trajectory\n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)\n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)\n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)\n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i + 1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "def k_fold_csv(input_directory, file_indices, output_index, output_directory):\n",
    "    os.makedirs(output_directory, exist_ok=True)    \n",
    "    output_file = os.path.join(output_directory, f'a50{output_index}.csv')\n",
    "    input_files = [f'B50{i}.csv' for i in file_indices]\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in input_files:\n",
    "        file_path = os.path.join(input_directory, file)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"File {file_path} does not exist and will be skipped.\")   \n",
    "    combined_df = combined_df.sort_values(by='trajectory')\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3, x4 = generate_random_values()\n",
    "    initial_conditions = [generate_random_values_based_on_c() for _ in range(m)]\n",
    "    forward_trajectories, backward_trajectories, t1, t2 = generate_data(initial_conditions)\n",
    "    save_data(forward_trajectories, backward_trajectories, t1, t2)\n",
    "    data = np.genfromtxt(os.path.join(output_director, '50.csv'), delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()\n",
    "    file_indices_list = [\n",
    "        [1, 2, 3, 4],\n",
    "        [1, 2, 3, 5],\n",
    "        [1, 2, 4, 5],\n",
    "        [1, 3, 4, 5],\n",
    "        [2, 3, 4, 5]\n",
    "    ]\n",
    "    for i, file_indices in enumerate(file_indices_list, start=1):\n",
    "        k_fold_csv(output_directory, file_indices, i, output_directoryk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472424a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "input_directory = r'../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N40/Traj_data'\n",
    "df14 = pd.read_csv(os.path.join(input_directory, '50.csv')) # 50.csv, saved names of the data\n",
    "Br = pd.read_csv('../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40/50.csv')\n",
    "tr = Br.groupby('trajectory').size()\n",
    "re1 = int(round(tr.mean()))\n",
    "rows_per_file = re1 \n",
    "num_files = len(df14) // rows_per_file\n",
    "data_chunks = [df14.iloc[i * rows_per_file:(i + 1) * rows_per_file].iloc[:, :-1] for i in range(num_files)]\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "for i, chunk in enumerate(data_chunks):\n",
    "    chunk.to_csv(os.path.join(output_directory, f'tr_{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b7167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
