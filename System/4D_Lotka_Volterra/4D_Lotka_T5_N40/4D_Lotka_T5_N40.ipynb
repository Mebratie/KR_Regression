{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b9f918",
   "metadata": {},
   "source": [
    "  \\begin{equation}\\label{eq:LVln}\n",
    "    \\begin{gathered}\n",
    "      \\dot{x}_{1}=x_{1}(3-x_{2}-x_{3}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{2}=x_{2}(x_{1}-x_{3})\\,,\\\\\n",
    "      \\dot{x}_{3}=x_{3}(-1+x_{1}+x_{2}-x_{4})\\,,\\quad\n",
    "      \\dot{x}_{4}=x_{4}(-2+x_{1}+x_{3})\\,,\n",
    "    \\end{gathered}\n",
    "  \\end{equation}\n",
    "  $x_5=\\ln(x_1), x_6=\\ln(x_2), x_7=\\ln(x_3), x_8=\\ln(x_4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c57e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3, x4, x5):\n",
      "(2.205388225869987, 1.2062278945128875, 1.5307491938736708, 2.6849314040666306)\n",
      "(2.7460765262137317, 3.523211926739394, 0.694466261113357, 0.7189190895588493)\n",
      "(2.8538016249298073, 1.12336102628843, 2.805268479911076, 3.9328444287631514)\n",
      "(3.16319723693973, 1.1339493117089958, 1.802131201643952, 2.138595097797396)\n",
      "(3.260958700058176, 1.242064692468134, 2.3907957659485546, 2.0215890762019892)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "output_director = r'../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "m = 5  # number of trajectory\n",
    "m1 = 21  # data point per trajectory divided by 2, which means the total data point is m*(2m1)=40\n",
    "m2 = 20\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "def generate_random_values_based_on_c():\n",
    "    x1 = random.uniform(0.5, 4)\n",
    "    x2 = random.uniform(0.3, 4)\n",
    "    x3 = random.uniform(0.2, 4)\n",
    "    x4 = random.uniform(0.4, 4)\n",
    "    return x1, x2, x3, x4\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0:\n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3, x4 = y\n",
    "        f = np.array([x1 * (3 - x2 - x3 - x4), x2 * (x1 - x3), x3 * (-1 + x1 + x2 - x4), x4 * (-2 + x1 + x3)])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    t1 = np.linspace(0, 10, m1) # forward\n",
    "    t2 = np.linspace(0, 10, m2) # backward\n",
    "    forward_trajectories = []\n",
    "    backward_trajectories = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3, x4, x5):\")\n",
    "    for initial_condition in initial_conditions:\n",
    "        print(initial_condition) \n",
    "        forward_trajectory = odeint(normalized_system, initial_condition, t1)\n",
    "        backward_trajectory = odeint(normalized_system, initial_condition, -t2)\n",
    "        forward_trajectories.append(forward_trajectory[:m1])\n",
    "        backward_trajectories.append(backward_trajectory[:m2])\n",
    "    return forward_trajectories, backward_trajectories, t1[:m1], t2[:m2]\n",
    "def save_data(forward_trajectories, backward_trajectories, t1, t2):\n",
    "    num_variables = 8 \n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')    \n",
    "    with open(os.path.join(output_director, '50.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, (forward_data, backward_data) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "            for j in range(len(t1)):\n",
    "                forward_row = forward_data[j].tolist()\n",
    "                forward_row += [math.log(max(x, 1e-10)) for x in forward_row[:num_variables - 1]]\n",
    "                forward_row += [r + 1]\n",
    "                writer.writerow(forward_row)\n",
    "            for j in range(1, len(t2)):  # Exclude initial conditions for backward trajectory\n",
    "                backward_row = backward_data[j].tolist()\n",
    "                backward_row += [math.log(max(x, 1e-10)) for x in backward_row[:num_variables - 1]]\n",
    "                backward_row += [r + 1]\n",
    "                writer.writerow(backward_row)  \n",
    "    output_directory1 = r'../../../results/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (forward_sol, backward_sol) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "        for j in range(forward_sol.shape[1]):\n",
    "            plt.plot(t1, forward_sol[:, j])\n",
    "            plt.plot(-t2, backward_sol[:, j])  # Exclude initial conditions for backward trajectory\n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)\n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)\n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)\n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i + 1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3, x4 = generate_random_values()\n",
    "    initial_conditions = [generate_random_values_based_on_c() for _ in range(m)]\n",
    "    forward_trajectories, backward_trajectories, t1, t2 = generate_data(initial_conditions)\n",
    "    save_data(forward_trajectories, backward_trajectories, t1, t2)\n",
    "    data = np.genfromtxt(os.path.join(output_director, '50.csv'), delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472424a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "input_directory = r'../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40'\n",
    "output_directory = r'../../../Data/4D_Lotka_Volterra/4D_Lotka_T5_N40/Traj_data'\n",
    "df14 = pd.read_csv(os.path.join(input_directory, '50.csv')) # 50.csv, saved names of the data\n",
    "Br = pd.read_csv('../../../System/4D_Lotka_Volterra/4D_Lotka_T5_N40/50.csv')\n",
    "tr = Br.groupby('trajectory').size()\n",
    "re1 = int(round(tr.mean()))\n",
    "rows_per_file = re1 \n",
    "num_files = len(df14) // rows_per_file\n",
    "data_chunks = [df14.iloc[i * rows_per_file:(i + 1) * rows_per_file].iloc[:, :-1] for i in range(num_files)]\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "for i, chunk in enumerate(data_chunks):\n",
    "    chunk.to_csv(os.path.join(output_directory, f'tr_{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b7167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
