{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dec082a",
   "metadata": {},
   "source": [
    "  \\begin{equation}\\label{eq:ndlm}\n",
    "    \\dot{x}_1=\\sigma x_2\\,,\\quad \\dot{x}_2=-x_1x_3+rx_1\\,,\\quad \\dot{x}_3=x_1x_2\n",
    "  \\end{equation}\n",
    "  $x_4=\\sigma, x_5=r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40164d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3, x4, x5):\n",
      "(-1.0726120210934997, -0.04078084925490133, 0.7930986933187246, 2.3847518944228216, 1.154438446668039)\n",
      "(0.8461294528710157, 0.7763342887491076, 0.7528323922612232, 2.223686015872143, 1.5057863117395063)\n",
      "(0.7211496899266301, 1.6611755257204726, 0.558280461319159, 2.8231755977548842, 0.7562552631377748)\n",
      "(0.6090873473883973, -0.0990880277348003, 0.7887897804253013, 1.9036618793712552, 0.7511734367061232)\n",
      "(0.3241098605891368, 1.0499216299197571, 0.3880559756851785, 3.526859587480848, 1.8964931614076812)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "output_directory = r'../../../Data/Lorenz_System/Lorenz_System_T5_10'\n",
    "output_director = r'../../../System/Lorenz_System/Lorenz_System_T5_10'\n",
    "m = 5 # number of trajectory\n",
    "m1 = 6 # data point per trajectory divided by 2, which means the total data point is m*(2m1)=40\n",
    "m2 =5 \n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(-2, 2)\n",
    "    x2 = random.uniform(-2, 2)\n",
    "    x3 = random.uniform(0, 1)\n",
    "    x4 = random.uniform(0.1, 4)\n",
    "    x5 = random.uniform(0.1, 2)\n",
    "    return x1, x2, x3, x4, x5\n",
    "def calculate_c(x1, x3, x4):\n",
    "    c = 1/2 * x1**2 - x4 * x3\n",
    "    return c\n",
    "def generate_random_values_based_on_c(c):\n",
    "    x1 = random.uniform(-2, 2)\n",
    "    x2 = random.uniform(-2, 2)\n",
    "    x4 = random.uniform(0.1, 4)\n",
    "    x5 = random.uniform(0.1, 2)\n",
    "    x3 = (x1**2 - c) / (2 * x4)\n",
    "    return x1, x2, x3, x4, x5\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0: \n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3, x4, x5 = y\n",
    "        f = np.array([x4 * x2, x1 * (x5 - x3), x1 * x2, 0, 0])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    t1 = np.linspace(0, 10, m1) # forward\n",
    "    t2 = np.linspace(0, 10, m2) # backward\n",
    "    forward_trajectories = []\n",
    "    backward_trajectories = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3, x4, x5):\")\n",
    "    for initial_condition in initial_conditions:\n",
    "        print(initial_condition) \n",
    "        forward_trajectory = odeint(normalized_system, initial_condition, t1)\n",
    "        backward_trajectory = odeint(normalized_system, initial_condition, -t2)\n",
    "        forward_trajectories.append(forward_trajectory[:m1])\n",
    "        backward_trajectories.append(backward_trajectory[:m2])\n",
    "    return forward_trajectories, backward_trajectories, t1[:m1], t2[:m2]\n",
    "def save_data(forward_trajectories, backward_trajectories, t1, t2):\n",
    "    num_variables = 5 \n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')    \n",
    "    with open(os.path.join(output_director, '50.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, (forward_data, backward_data) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "            for j in range(len(t1)):\n",
    "                forward_row = forward_data[j].tolist() + [r + 1]\n",
    "                writer.writerow(forward_row)\n",
    "            for j in range(1, len(t2)):  # Exclude initial conditions for backward trajectory\n",
    "                backward_row = backward_data[j].tolist() + [r + 1]\n",
    "                writer.writerow(backward_row)     \n",
    "    output_directory1 = r'../../../results/Lorenz_System/Lorenz_System_T5_10'\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, (forward_sol, backward_sol) in enumerate(zip(forward_trajectories, backward_trajectories)):\n",
    "        for j in range(forward_sol.shape[1]):\n",
    "            plt.plot(t1, forward_sol[:, j])\n",
    "            plt.plot(-t2, backward_sol[:, j])  # Exclude initial conditions for backward trajectory\n",
    "    plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "    plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None    \n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)   \n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)   \n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)    \n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i+1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point) \n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3, x4, x5 = generate_random_values()\n",
    "    c = calculate_c(x1, x3, x4)\n",
    "    initial_conditions = [generate_random_values_based_on_c(c) for _ in range(m)]\n",
    "    forward_trajectories, backward_trajectories, t1, t2 = generate_data(initial_conditions)\n",
    "    save_data(forward_trajectories, backward_trajectories, t1, t2)\n",
    "    data = np.genfromtxt(os.path.join(output_director, '50.csv'), delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b157fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "input_directory = r'../../../System/Lorenz_System/Lorenz_System_T5_10'\n",
    "output_directory = r'../../../Data/Lorenz_System/Lorenz_System_T5_10/Traj_data'\n",
    "df14 = pd.read_csv(os.path.join(input_directory, '50.csv')) # 50.csv, saved names of the data\n",
    "Br = pd.read_csv('../../../System/Lorenz_System/Lorenz_System_T5_10/50.csv')\n",
    "tr = Br.groupby('trajectory').size()\n",
    "re1 = int(round(tr.mean()))\n",
    "rows_per_file = re1 \n",
    "num_files = len(df14) // rows_per_file\n",
    "data_chunks = [df14.iloc[i * rows_per_file:(i + 1) * rows_per_file].iloc[:, :-1] for i in range(num_files)]\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "for i, chunk in enumerate(data_chunks):\n",
    "    chunk.to_csv(os.path.join(output_directory, f'tr_{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1247b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
