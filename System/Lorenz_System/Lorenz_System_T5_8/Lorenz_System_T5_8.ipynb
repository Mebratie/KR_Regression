{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "625e09c4",
   "metadata": {},
   "source": [
    "  \\begin{equation}\\label{eq:ndlm}\n",
    "    \\dot{x}_1=\\sigma x_2\\,,\\quad \\dot{x}_2=-x_1x_3+rx_1\\,,\\quad \\dot{x}_3=x_1x_2\n",
    "  \\end{equation}\n",
    "  $x_4=\\sigma, x_5=r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241baf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data (x1, x2, x3, x4, x5):\n",
      "(1.7827800764568322, -1.5084164701287923, 0.33158868524396456, 2.917912764498523, 1.8031404042130865)\n",
      "(0.6546077905661822, -0.5779717615531772, -0.3866823863512159, 1.053448199122548, 0.25872554560497185)\n",
      "(-0.3176691555321596, 0.2112861787091158, -0.17593439218046808, 3.246373207661084, 0.7943848105907415)\n",
      "(0.23249867399106572, 1.1753180960546663, -0.2548666429928777, 2.3328973912913376, 0.5290182004877967)\n",
      "(-1.246676234212611, 0.10860286820022669, 0.04147063351602029, 3.7495273166283525, 1.7043479495912257)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "output_directory = r'../../../Data/Lorenz_System/Lorenz_System_T5_8'\n",
    "output_director = r'../../../System/Lorenz_System/Lorenz_System_T5_8'\n",
    "def generate_random_values():\n",
    "    x1 = random.uniform(-2, 2)\n",
    "    x2 = random.uniform(-2, 2)\n",
    "    x3 = random.uniform(0, 1)\n",
    "    x4 = random.uniform(0.1, 4)\n",
    "    x5 = random.uniform(0.1, 2)\n",
    "    return x1, x2, x3, x4, x5\n",
    "def calculate_c(x1, x3, x4):\n",
    "    c = 1/2 * x1**2 - x4 * x3\n",
    "    return c\n",
    "def generate_random_values_based_on_c(c):\n",
    "    x1 = random.uniform(-2, 2)\n",
    "    x2 = random.uniform(-2, 2)\n",
    "    x4 = random.uniform(0.1, 4)\n",
    "    x5 = random.uniform(0.1, 2)\n",
    "    x3 = (x1**2 - c) / (2 * x4)\n",
    "    return x1, x2, x3, x4, x5\n",
    "def generate_data(initial_conditions):\n",
    "    def normalize(vector):\n",
    "        norm = np.linalg.norm(vector)\n",
    "        if norm == 0: \n",
    "            return vector\n",
    "        return vector / norm\n",
    "    def normalized_system(y, t):\n",
    "        x1, x2, x3, x4, x5 = y\n",
    "        f = np.array([x4 * x2, x1 * (x5 - x3), x1 * x2, 0, 0])\n",
    "        normalized_f = normalize(f)\n",
    "        return normalized_f\n",
    "    num_trajectories = 5\n",
    "    t_forward = np.linspace(0, 10, 4) # 4 data points forward\n",
    "    t_backward = np.linspace(0, 10, 4)[::-1] # 4 data points backward\n",
    "    all_forward_trajectory_data = []\n",
    "    all_backward_trajectory_data = []\n",
    "    initial_conditions_to_print = []\n",
    "    print(\"Initial data (x1, x2, x3, x4, x5):\")  \n",
    "    for i, initial_condition in enumerate(initial_conditions):\n",
    "        print(f\"({initial_condition[0]}, {initial_condition[1]}, {initial_condition[2]}, {initial_condition[3]}, {initial_condition[4]})\")\n",
    "        forward_sol = odeint(normalized_system, initial_condition, t_forward)\n",
    "        backward_sol = odeint(normalized_system, initial_condition, t_backward)\n",
    "        all_forward_trajectory_data.append(forward_sol)\n",
    "        all_backward_trajectory_data.append(backward_sol)   \n",
    "    num_variables = 5 # Adjust number of variables that we need for the regression accordingly\n",
    "    column_names = [f'x{i+1}' for i in range(num_variables)]\n",
    "    column_names.append('trajectory')    \n",
    "    with open(os.path.join(output_director, '50.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        for r, (forward_data, backward_data) in enumerate(zip(all_forward_trajectory_data, all_backward_trajectory_data)):\n",
    "            for j in range(len(t_forward)):\n",
    "                forward_row = forward_data[j].tolist() + [r + 1]\n",
    "                backward_row = backward_data[j].tolist() + [r + 1]\n",
    "                writer.writerow(forward_row)\n",
    "                writer.writerow(backward_row)\n",
    "    output_directory1 = r'../../../results/Lorenz_System/Lorenz_System_T5_8'\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for i, (forward_sol, backward_sol) in enumerate(zip(all_forward_trajectory_data, all_backward_trajectory_data)):\n",
    "#         for j in range(forward_sol.shape[1]):\n",
    "#             plt.plot(t_forward, forward_sol[:, j])\n",
    "#             plt.plot(-t_backward, backward_sol[:, j])\n",
    "#     plt.savefig(os.path.join(output_directory1, 'trajectory.png'))\n",
    "#     plt.close()\n",
    "def split_data():\n",
    "    trajectories = {}\n",
    "    column_names = None    \n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'r') as trainfile:\n",
    "        reader = csv.DictReader(trainfile)\n",
    "        column_names = reader.fieldnames\n",
    "        for row in reader:\n",
    "            trajectory = float(row['trajectory'])\n",
    "            if trajectory not in trajectories:\n",
    "                trajectories[trajectory] = []\n",
    "            trajectory_data = {key: float(value) for key, value in row.items()}\n",
    "            trajectories[trajectory].append(trajectory_data)   \n",
    "    for traj_points in trajectories.values():\n",
    "        random.shuffle(traj_points)   \n",
    "    num_points_per_file = len(next(iter(trajectories.values()))) // 5  # divide into five splits (n stratify)    \n",
    "    for i in range(5):  # Five-fold cross-validation\n",
    "        output_filename = f'B50{i+1}.csv'\n",
    "        with open(os.path.join(output_directory, output_filename), 'w', newline='') as output_file:\n",
    "            writer = csv.DictWriter(output_file, fieldnames=column_names)\n",
    "            writer.writeheader()\n",
    "            for trajectory, points in trajectories.items():\n",
    "                for point in points[i * num_points_per_file: (i + 1) * num_points_per_file]:\n",
    "                    writer.writerow(point)\n",
    "if __name__ == \"__main__\":\n",
    "    x1, x2, x3, x4, x5 = generate_random_values()\n",
    "    c = calculate_c(x1, x3, x4)\n",
    "    initial_conditions = [generate_random_values_based_on_c(c) for _ in range(5)]\n",
    "    generate_data(initial_conditions)\n",
    "    data = np.genfromtxt('50.csv', delimiter=',', names=True)\n",
    "    training_data = []\n",
    "    holdout_data = []\n",
    "    for r in range(1, 6):  # this represents the number of initial data is 5. i.e., (1,6) means 5 initial data\n",
    "        trajectory_subset = data[data['trajectory'] == r]\n",
    "        train_set, holdout_set = train_test_split(trajectory_subset, test_size=0.2, random_state=42)\n",
    "        training_data.extend(train_set)\n",
    "        holdout_data.extend(holdout_set)\n",
    "    column_names = data.dtype.names\n",
    "    with open(os.path.join(output_directory, 'trainingp_data50.csv'), 'w', newline='') as trainfile:\n",
    "        writer = csv.writer(trainfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in training_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    with open(os.path.join(output_directory, 'holdoutp_data50.csv'), 'w', newline='') as holdfile:\n",
    "        writer = csv.writer(holdfile)\n",
    "        writer.writerow(column_names)\n",
    "        for row in holdout_data:\n",
    "            writer.writerow([row[col] for col in column_names])\n",
    "    split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bd00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "input_directory = r'../../../System/Lorenz_System/Lorenz_System_T5_8'\n",
    "output_directory = r'../../../Data/Lorenz_System/Lorenz_System_T5_8/Traj_data'\n",
    "df14 = pd.read_csv(os.path.join(input_directory, '50.csv')) # 50.csv, saved names of the data\n",
    "Br = pd.read_csv('../../../System/Lorenz_System/Lorenz_System_T5_8/50.csv')\n",
    "tr = Br.groupby('trajectory').size()\n",
    "re1 = int(round(tr.mean()))\n",
    "rows_per_file = re1 \n",
    "num_files = len(df14) // rows_per_file\n",
    "data_chunks = [df14.iloc[i * rows_per_file:(i + 1) * rows_per_file].iloc[:, :-1] for i in range(num_files)]\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "for i, chunk in enumerate(data_chunks):\n",
    "    chunk.to_csv(os.path.join(output_directory, f'tr_{i + 1}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e90cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
