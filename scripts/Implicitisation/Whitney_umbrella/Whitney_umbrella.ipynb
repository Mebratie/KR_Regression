{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da5f1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 1e-07}\n",
      "Best RMSE: 0.012500000000023742\n",
      "\n",
      "\n",
      "Candidate Conservation Law:\n",
      "                          3                           2                       \n",
      "- 4.4676880255413215e-8⋅x₁  - 5.0920713352687447e-8⋅x₁ ⋅x₂ - 0.499996179307546\n",
      "\n",
      "     2                              2                              2          \n",
      "97⋅x₁ ⋅x₃ - 5.1055091536235451e-8⋅x₁  + 1.1649293443805543e-7⋅x₁⋅x₂  - 4.82495\n",
      "\n",
      "                                                                              \n",
      "61348254547e-9⋅x₁⋅x₂⋅x₃ + 1.9224690896071234e-8⋅x₁⋅x₂ + 1.5467945564082456e-7⋅\n",
      "\n",
      "     2                                                                        \n",
      "x₁⋅x₃  - 2.2930176626044518e-7⋅x₁⋅x₃ + 4.4091455727798823e-8⋅x₁ + 7.9802118728\n",
      "\n",
      "           3                           2                            2         \n",
      "58208e-8⋅x₂  - 3.4525313448901111e-7⋅x₂ ⋅x₃ + 0.49999652676103761⋅x₂  + 5.2849\n",
      "\n",
      "                     2                                                        \n",
      "099299069613e-7⋅x₂⋅x₃  - 7.6436480582389027e-7⋅x₂⋅x₃ + 2.100200172145566e-7⋅x₂\n",
      "\n",
      "                           3                           2                      \n",
      " - 1.4602945306292723e-6⋅x₃  + 2.3969058049165288e-6⋅x₃  - 9.9944852277513568e\n",
      "\n",
      "                           \n",
      "-7⋅x₃ + 7.07223677398616e-8\n",
      "\n",
      "\n",
      "Final Candidate CL:\n",
      "                        2                            2\n",
      "- 0.49999617930754697⋅x₁ ⋅x₃ + 0.49999652676103761⋅x₂ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sympy import symbols, simplify, lambdify, Function, diff\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "%matplotlib inline\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\mebratie\\\\Desktop\\\\KR\\\\KR_Regression\\\\System\\\\Implicitisation\\\\Whitney_umbrella\\\\50.csv')\n",
    "X = df2.iloc[:, :-1]\n",
    "y = df2.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.to_csv('C:\\\\Users\\\\mebratie\\\\Desktop\\\\KR\\\\KR_Regression\\\\results\\\\Implicitisation\\\\Whitney_umbrella\\\\X_train.csv', index=False)\n",
    "y_train = y_train.astype(float)\n",
    "def polynomial_kernel(X, Y, degree=3):\n",
    "    return (1 + np.dot(X, Y.T)) ** degree\n",
    "param_grid = {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kr_model = KernelRidge(kernel=polynomial_kernel)\n",
    "grid_search = GridSearchCV(kr_model, param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best RMSE:\", -grid_search.best_score_)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "grid_search.best_estimator_\n",
    "y_pred = grid_search.predict(X_test)\n",
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    fit_K\n",
    "    predict_K\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'polynomial': polynomial_kernel,\n",
    "    }\n",
    "    def __init__(self, kernel='polynomial', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        self.fit_intercept_ = False\n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        params['degree'] = kwargs.get('degree', 3)\n",
    "        return params\n",
    "    def fit_K(self, K, y, **kwargs):\n",
    "        pass\n",
    "    def decision_function_K(self, K):\n",
    "        pass\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        K = self.kernel_function_(self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        return self.fit_K(K, y, **kwargs)\n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return self.decision_function_K(K_x)\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    def predict_K(self, K):\n",
    "        pass\n",
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, alpha=0.1, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "    def fit_K(self, K, y):\n",
    "        n = K.shape[0]\n",
    "        assert (n == len(y))\n",
    "        A = K + self.alpha*np.identity(n)\n",
    "        self.eta = np.linalg.solve(A , y)\n",
    "        return self\n",
    "    def decision_function_K(self, K_x):\n",
    "        return K_x.dot(self.eta)\n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)\n",
    "    def predict_K(self, K_x):\n",
    "        return self.decision_function_K(K_x)\n",
    "kernel = 'polynomial'\n",
    "kr_model = KernelRidgeRegression(\n",
    "    kernel=kernel,\n",
    "    alpha=grid_search.best_params_['alpha'],\n",
    "    )\n",
    "kr_model.fit(X_train, y_train)\n",
    "eta = kr_model.eta\n",
    "x1, x2, x3 = sp.symbols('x1 x2 x3')\n",
    "def multilinear_coefficient(n, *ks):\n",
    "    numerator = math.factorial(n)\n",
    "    denominator = 1\n",
    "    for k in ks:\n",
    "        denominator *= math.factorial(k)\n",
    "    return numerator // denominator\n",
    "def multilinear_expansion(variables, n, row):\n",
    "    expansions = []\n",
    "    for ks in itertools.product(range(n + 1), repeat=len(variables)):\n",
    "        if sum(ks) == n:\n",
    "            coefficient = multilinear_coefficient(n, *ks)\n",
    "            values = [row[var] ** k if var != '1' else 1 for var, k in zip(variables, ks)]\n",
    "            term_value = coefficient * math.prod(values)\n",
    "            expansions.append(term_value)\n",
    "    return expansions[::-1]\n",
    "def multilinear_expansion1(variables1, n1):\n",
    "    expansions1 = []  \n",
    "    for ks in itertools.product(range(n1 + 1), repeat=len(variables1)):\n",
    "        if sum(ks) == n1:\n",
    "            terms1 = [f\"{var}**{k}\" if k != 0 else f\"{var}\" for var, k in zip(variables1, ks) if k != 0]\n",
    "            term1 = \" * \".join(terms1)\n",
    "            expansions1.append(term1)\n",
    "    return expansions1[::-1]\n",
    "def generate_inner_products(coefficients, terms):\n",
    "    inner_products = [f\"{c}*{t}\" for c, t in zip(coefficients, terms)]\n",
    "    return inner_products\n",
    "num_variables = 3\n",
    "data = pd.read_csv('C:\\\\Users\\\\mebratie\\\\Desktop\\\\KR\\\\KR_Regression\\\\results\\\\Implicitisation\\\\Whitney_umbrella\\\\X_train.csv')\n",
    "variables = ['c'] + [f'x{i}' for i in range(1, num_variables + 1)]\n",
    "n = 3\n",
    "data['c'] = 1\n",
    "variables1 = ['1'] + [f'x{i}' for i in range(1, num_variables + 1)]\n",
    "n1 = 3\n",
    "all_entries = []\n",
    "for index, row in data.iterrows():\n",
    "    result = multilinear_expansion(variables, n, row)\n",
    "    result1 = multilinear_expansion1(variables1, n1)\n",
    "    expressions = generate_inner_products(result, result1)\n",
    "    all_entries.append(expressions)\n",
    "total_sum = 0\n",
    "for entry_index, (entry, alpha) in enumerate(zip(all_entries, eta), 1):\n",
    "    entry_sum = 0\n",
    "    for term in entry:\n",
    "        result = alpha * sp.sympify(term)\n",
    "        entry_sum += result\n",
    "    total_sum += entry_sum\n",
    "coefficients = list(total_sum.as_coefficients_dict().values())\n",
    "terms = list(total_sum.as_coefficients_dict().keys())\n",
    "filtered_terms = [term for coeff, term in zip(coefficients, terms) if abs(coeff) > 0.0001]\n",
    "filtered_expression = sum(sp.Mul(coeff, term) for coeff, term in zip(coefficients, terms) if term in filtered_terms)\n",
    "print(\"Candidate Conservation Law:\")\n",
    "sp.pprint(total_sum)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "with open(\"C:\\\\Users\\\\mebratie\\\\Desktop\\\\KR\\\\KR_Regression\\\\results\\\\Implicitisation\\\\Whitney_umbrella\\\\total_sum.txt\", \"w\") as file:\n",
    "    file.write(str(total_sum))\n",
    "print(\"Final Candidate CL:\")\n",
    "sp.pprint(filtered_expression)\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da73ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
