{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882c1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter polynomial kernel d = 2\n",
      "Enter c =  1\n",
      "Candidate Conservation Law:\n",
      "                        2                                                     \n",
      "- 0.00168333556149846⋅x₁  + 2.192518454118e-11⋅x₁⋅x₂ - 6.22409848270375e-11⋅x₁\n",
      "\n",
      "                                                                              \n",
      "⋅x₃ + 6.67713565861983e-10⋅x₁⋅x₄ + 2.93351532843801e-10⋅x₁⋅x₅ - 1.338299611213\n",
      "\n",
      "                                  2                                           \n",
      "48e-9⋅x₁ + 0.000259451496446808⋅x₂  + 4.70832143347095e-11⋅x₂⋅x₃ + 5.411230925\n",
      "\n",
      "                                                                              \n",
      "15083e-11⋅x₂⋅x₄ - 1.06542389439936e-10⋅x₂⋅x₅ + 5.03504399632093e-11⋅x₂ + 0.000\n",
      "\n",
      "                  2                                                           \n",
      "259451502981979⋅x₃  + 0.00336667119943368⋅x₃⋅x₄ - 0.000518902498786026⋅x₃⋅x₅ -\n",
      "\n",
      "                                                2                             \n",
      " 8.82291423406033e-10⋅x₃ + 0.0162278483514336⋅x₄  + 0.0298696652120447⋅x₄⋅x₅ +\n",
      "\n",
      "                                             2                                \n",
      " 0.0164706313924658⋅x₄ + 0.015117109485175⋅x₅  + 0.0170337472509645⋅x₅ + 0.004\n",
      "\n",
      "              \n",
      "83091757009014\n",
      "\n",
      "\n",
      "Final Conservation Law:\n",
      "                        2                          2                          \n",
      "- 0.00168333556149846⋅x₁  + 0.000259451496446808⋅x₂  + 0.000259451502981979⋅x₃\n",
      "\n",
      "2                                                                             \n",
      "  + 0.00336667119943368⋅x₃⋅x₄ - 0.000518902498786026⋅x₃⋅x₅ + 0.016227848351433\n",
      "\n",
      "    2                                                                         \n",
      "6⋅x₄  + 0.0298696652120447⋅x₄⋅x₅ + 0.0164706313924658⋅x₄ + 0.015117109485175⋅x\n",
      "\n",
      " 2                                              \n",
      "₅  + 0.0170337472509645⋅x₅ + 0.00483091757009014\n",
      "\n",
      "\n",
      "Candidate CL:\n",
      "                        2                          2                          \n",
      "- 0.00168333556149846⋅x₁  + 0.000259451496446808⋅x₂  + 0.000259451502981979⋅x₃\n",
      "\n",
      "2                                                         \n",
      "  + 0.00336667119943368⋅x₃⋅x₄ - 0.000518902498786026⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Simplified Candidate CL:\n",
      "                   2                       2                       2          \n",
      "3.24403055571447⋅x₁  - 0.500000476108317⋅x₂  - 0.500000488702535⋅x₃  - 6.48806\n",
      "\n",
      "                           \n",
      "125873363⋅x₃⋅x₄ + 1.0⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Generalisation Error (RMSE): 1.0674962272755592e-10\n",
      "\n",
      " Relative deviation: 7.279003467734509e-10\n",
      "\n",
      "[-0.00336667112299692⋅x₁  0.000518902992893616⋅x₂  0.000518903005963959⋅x₃ + 0\n",
      ".00336667119943368⋅x₄ - 0.000518902498786026⋅x₅  0.00336667119943368⋅x₃  -0.00\n",
      "0518902498786026⋅x₃]\n",
      "Second CL:\n",
      "                      2                                                       \n",
      "0.00623370042537406⋅x₁  + 2.27684998709238e-8⋅x₁⋅x₂ - 9.65738132113519e-8⋅x₁⋅x\n",
      "\n",
      "                                                                              \n",
      "₃ - 4.51915156803119e-8⋅x₁⋅x₄ - 9.51568634126269e-8⋅x₁⋅x₅ - 6.22443191016019e-\n",
      "\n",
      "                            2                                                 \n",
      "8⋅x₁ + 0.0203321774563645⋅x₂  + 1.22719691761053e-8⋅x₂⋅x₃ + 7.10893092938414e-\n",
      "\n",
      "                                                                              \n",
      "9⋅x₂⋅x₄ + 1.72900613444784e-8⋅x₂⋅x₅ - 1.53171239411427e-9⋅x₂ + 0.0203321513641\n",
      "\n",
      "      2                                                                       \n",
      "032⋅x₃  - 0.0124675033029111⋅x₃⋅x₄ - 0.0406644706311372⋅x₃⋅x₅ + 8.411368744325\n",
      "\n",
      "                                 2                                            \n",
      "75e-10⋅x₃ - 0.0410433073654101⋅x₄  + 0.0514525657474408⋅x₄⋅x₅ - 0.182692489208\n",
      "\n",
      "                             2                                            \n",
      "045⋅x₄ + 0.127362561435704⋅x₅  + 0.0468220684302708⋅x₅ - 0.074605016032444\n",
      "\n",
      "\n",
      "Final Conservation Law:\n",
      "                      2                        2                        2     \n",
      "0.00623370042537406⋅x₁  + 0.0203321774563645⋅x₂  + 0.0203321513641032⋅x₃  - 0.\n",
      "\n",
      "                                                                         2    \n",
      "0124675033029111⋅x₃⋅x₄ - 0.0406644706311372⋅x₃⋅x₅ - 0.0410433073654101⋅x₄  + 0\n",
      "\n",
      "                                                                     2        \n",
      ".0514525657474408⋅x₄⋅x₅ - 0.182692489208045⋅x₄ + 0.127362561435704⋅x₅  + 0.046\n",
      "\n",
      "                                    \n",
      "8220684302708⋅x₅ - 0.074605016032444\n",
      "\n",
      "\n",
      "Candidate CL:\n",
      "                      2                        2                        2     \n",
      "0.00623370042537406⋅x₁  + 0.0203321774563645⋅x₂  + 0.0203321513641032⋅x₃  - 0.\n",
      "\n",
      "                                                 \n",
      "0124675033029111⋅x₃⋅x₄ - 0.0406644706311372⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Simplified Candidate CL:\n",
      "                     2                       2                       2        \n",
      "- 0.15329599349563⋅x₁  - 0.499998577155851⋅x₂  - 0.499997935508219⋅x₃  + 0.306\n",
      "\n",
      "                              \n",
      "594506442796⋅x₃⋅x₄ + 1.0⋅x₃⋅x₅\n",
      "\n",
      "\n",
      " Relative deviation: 0.00021967542692750348\n",
      "\n",
      "First sparse CL:\n",
      "                        2                          2                         2\n",
      "- 0.00178566747486487⋅x₁  + 8.05890035097696e-10⋅x₂  + 1.14976607276879e-9⋅x₃ \n",
      "\n",
      "                                                         \n",
      " + 0.00357133635140335⋅x₃⋅x₄ + 3.84436279034575e-10⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Simplified First sparse CL:\n",
      "                        2                            \n",
      "- 0.00178566747486487⋅x₁  + 0.00357133635140335⋅x₃⋅x₄\n",
      "\n",
      "\n",
      "Final First Sparse CL:\n",
      "                      2            \n",
      "- 0.499999803760627⋅x₁  + 1.0⋅x₃⋅x₄\n",
      "\n",
      "\n",
      "Second CL:\n",
      "                        2                         2                         2 \n",
      "- 8.08885880303721e-9⋅x₁  + 0.00452733295047449⋅x₂  + 0.00452732740785955⋅x₃  \n",
      "\n",
      "                                                       \n",
      "- 5.54557079944507e-9⋅x₃⋅x₄ - 0.00905469011605337⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Simplified second CL:\n",
      "                      2                         2                            \n",
      "0.00452733295047449⋅x₂  + 0.00452732740785955⋅x₃  - 0.00905469011605337⋅x₃⋅x₅\n",
      "\n",
      "\n",
      "Final Second Sparse CL:\n",
      "                      2                       2            \n",
      "- 0.499998662841904⋅x₂  - 0.499998050715496⋅x₃  + 1.0⋅x₃⋅x₅\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sympy import symbols, simplify, lambdify, Function, diff, Mul\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from cvxopt import matrix, solvers\n",
    "from qpsolvers import solve_qp\n",
    "from scipy.sparse import csc_matrix\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations_with_replacement\n",
    "from sympy import symbols, Matrix\n",
    "from scipy import sparse\n",
    "import ast\n",
    "import cvxpy as cp\n",
    "d = int(input(\"Enter polynomial kernel d = \"))\n",
    "c = int(input(\"Enter c =  \"))\n",
    "def compute_kernel_matrix(X, c, d):\n",
    "    n = X.shape[0]\n",
    "    K = (c + np.dot(X, X.T)) ** d\n",
    "    return K\n",
    "def solve_for_lambda(data, c, d, lambda_value):\n",
    "    B501_data = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/B501.csv')\n",
    "    traj_len = B501_data.groupby('trajectory').size()\n",
    "    rep = int(round(traj_len.mean()))\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I)\n",
    "    m = 5 # number of trajectory\n",
    "    num_y_variables = m\n",
    "    y_symbols = [sp.symbols(f'y{i}') for i in range(num_y_variables)]\n",
    "    y_pattern = [sp.symbols(f'y{i}') for i in range(m)]\n",
    "    y_repeated = np.repeat(y_pattern, rep, axis=0)\n",
    "    y = sp.Matrix([sp.symbols(f'y{i}') for i in range(m)])  \n",
    "    M_matrix = sp.Matrix(K_with_I_inv)\n",
    "    n = K.shape[0]\n",
    "    M = sp.zeros(n, m)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            start_idx = j * rep\n",
    "            end_idx = (j + 1) * rep\n",
    "            M[i, j] = sp.Add(*M_matrix[i, start_idx:end_idx])\n",
    "    M_transpose = M.transpose()\n",
    "    A = M_transpose @ M \n",
    "    A_np = np.array(A).astype(np.float64)\n",
    "    return A_np\n",
    "m = 5 # number of trajectory\n",
    "base_path = \"../../../Data/Lorenz_System/Lorenz_System_T5_40/\"\n",
    "file_names = [f\"B50{i}.csv\" for i in range(1, m+1)]\n",
    "filenames = [base_path + file_name for file_name in file_names]\n",
    "data_list = [np.loadtxt(filename, delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4)) for filename in filenames]\n",
    "data, data2, data3, data4, data5 = data_list\n",
    "solutions_combined = []\n",
    "for i in range(0, 8):\n",
    "    lambda_value = 10**(-i)\n",
    "    A_np_list = [solve_for_lambda(data_array, c=c, d=d, lambda_value=lambda_value) for data_array in data_list]\n",
    "    A1_np, A2_np, A3_np, A4_np, A5_np = A_np_list\n",
    "    As_p = np.mean(A_np_list, axis=0)\n",
    "    P = np.array(As_p)\n",
    "    q = np.zeros(m)\n",
    "    a = np.random.uniform(-3, 3, m)\n",
    "    G = np.zeros((0, m))\n",
    "    h = np.zeros(0)\n",
    "    A = a.reshape(1, -1)\n",
    "    P = csc_matrix(P)\n",
    "    G = csc_matrix(G)\n",
    "    A = csc_matrix(A) \n",
    "    b = np.array([1.0])\n",
    "    y = solve_qp(P, q, G, h, A, b, solver=\"clarabel\")\n",
    "    y_opt = y.flatten() if isinstance(y, np.ndarray) else np.array(y).flatten()\n",
    "    y_names = [sp.symbols(f'y{i}') for i in range(m)]\n",
    "    y_dict = {name: value for name, value in zip(y_names, y_opt)}\n",
    "    solutions_combined.append((lambda_value, y_dict))\n",
    "def compute_kernel_matrix(X, c, d):\n",
    "    n = X.shape[0]\n",
    "    K = (c + np.dot(X, X.T)) ** d\n",
    "    return K\n",
    "def solve_for_lambda(data, c, d, lambda_value, y_values):\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I)\n",
    "    y_repeated = np.repeat(y_values, len(data) // len(y_values))\n",
    "    alpha_sym = K_with_I_inv @ y_repeated\n",
    "    return K_with_I_inv, alpha_sym\n",
    "def generate_f_alpha_expression(alpha_sym, x1, x2, x3, x4, x5, x_q1_sym, x_q2_sym, x_q3_sym, x_q4_sym, x_q5_sym, c, d):\n",
    "    f_alpha = 0\n",
    "    for i in range(len(alpha_sym)):\n",
    "        f_alpha += alpha_sym[i] * (c + (x1[i] * x_q1_sym) + (x2[i] * x_q2_sym) + (x3[i] * x_q3_sym) + (x4[i] * x_q4_sym) + (x5[i] * x_q5_sym)) ** d\n",
    "    f_alpha_expanded = sp.expand(f_alpha)\n",
    "    f_alpha_collected = sp.collect(f_alpha_expanded, (x_q1_sym, x_q2_sym, x_q3_sym, x_q4_sym, x_q5_sym))\n",
    "    return f_alpha_collected\n",
    "def process_dataset(file_path, c, d, lambda_values, y_values_dicts):\n",
    "    data = np.loadtxt(file_path, delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4))\n",
    "    x1, x2, x3, x4, x5 = data[:, 0], data[:, 1], data[:, 2], data[:, 3], data[:, 4]\n",
    "    K_with_I_inv_list = []\n",
    "    alpha_sym_list = []\n",
    "    f_alpha_expression_list = []\n",
    "    for lambda_val, (_, y_values_dict) in zip(lambda_values, y_values_dicts):\n",
    "        K_with_I_inv, alpha_sym = solve_for_lambda(data, c, d, lambda_val, list(y_values_dict.values()))\n",
    "        x_q1_sym, x_q2_sym, x_q3_sym, x_q4_sym, x_q5_sym = sp.symbols('x1 x2 x3 x4 x5')\n",
    "        K_with_I_inv_list.append(K_with_I_inv)\n",
    "        alpha_sym_list.append(alpha_sym)\n",
    "        f_alpha_expression = generate_f_alpha_expression(alpha_sym, x1, x2, x3, x4, x5, x_q1_sym, x_q2_sym, x_q3_sym, x_q4_sym, x_q5_sym, c, d)\n",
    "        f_alpha_expression_list.append(f_alpha_expression)\n",
    "    \n",
    "    return K_with_I_inv_list, alpha_sym_list, f_alpha_expression_list\n",
    "lamda = 8\n",
    "lambda_values = [10**(-i) for i in range(lamda)]\n",
    "y_values_dicts_list = solutions_combined\n",
    "base_path = \"../../../Data/Lorenz_System/Lorenz_System_T5_40/\"\n",
    "file_names = [f\"B50{i}.csv\" for i in range(1, 6)]\n",
    "file_paths = [base_path + file_name for file_name in file_names]\n",
    "datasets = [pd.read_csv(path) for path in file_paths]\n",
    "B501_data = datasets[0]\n",
    "dr1 = datasets[-1]\n",
    "traj_len = B501_data.groupby('trajectory').size()\n",
    "rep4 = int(round(traj_len.mean()))\n",
    "results = [process_dataset(path, c, d, lambda_values, y_values_dicts_list) for path in file_paths]\n",
    "f_vectors = []\n",
    "for _, _, f_alpha_expr in results:\n",
    "    f_vector = [[] for _ in range(len(f_alpha_expr))]\n",
    "    for index, row in dr1.iterrows():\n",
    "        for i, expr in enumerate(f_alpha_expr):\n",
    "            value = eval(str(expr), globals(), row.to_dict())\n",
    "            f_vector[i].append(value)\n",
    "    f_vectors.append(f_vector)\n",
    "h_values = [list(y_dict[1].values()) for y_dict in y_values_dicts_list]\n",
    "y_B_values = []\n",
    "for h in h_values:\n",
    "    y_B_values.extend([np.repeat(h, rep4) for _ in range(8)])\n",
    "rmse_values = {}\n",
    "for i, f_vector in enumerate(f_vectors):\n",
    "    rmse_values[f\"B50{i+1}\"] = [np.sqrt(mean_squared_error(y, f)) for y, f in zip(y_B_values[i*8:(i+1)*8], f_vector)]\n",
    "min_rmse_info = {}\n",
    "for key, rmse_list in rmse_values.items():\n",
    "    min_rmse = min(rmse_list)\n",
    "    min_index = rmse_list.index(min_rmse)\n",
    "    min_rmse_info[key] = (min_rmse, min_index)\n",
    "min_rmse = float('inf')  \n",
    "min_index = None\n",
    "dataset_key = None\n",
    "for key, rmse_list in rmse_values.items():\n",
    "    for index, value in enumerate(rmse_list):\n",
    "        if value < min_rmse:\n",
    "            min_rmse = value\n",
    "            min_index = index\n",
    "            dataset_key = key\n",
    "file_index = min_index // 8 + 1\n",
    "sub_index = min_index % 8\n",
    "lambda_values = [10**(-i) for i in range(lamda)]\n",
    "h_value = h_values[-1]\n",
    "# h_value = h_values[sub_index]\n",
    "df2 = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "m = df2['trajectory'].nunique()\n",
    "df2['trajectory'] = df2['trajectory'].replace({i: h_value[i-1] for i in range(1, m+1)})\n",
    "X_train = df2.iloc[:, :-1]\n",
    "y_train = df2.iloc[:, -1]\n",
    "X_train.to_csv('../../../results/Lorenz_System/Lorenz_System_T5_40/X_train.csv', index=False)\n",
    "y_train = y_train.astype(float)\n",
    "X_train = X_train.astype(float)\n",
    "def polynomial_kernel(X, Y, degree=d):\n",
    "    return (1 + np.dot(X, Y.T)) ** degree\n",
    "param_grid = {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kr_model = KernelRidge(kernel=polynomial_kernel)\n",
    "grid_search = GridSearchCV(kr_model, param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    fit_K\n",
    "    predict_K\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'polynomial': polynomial_kernel,\n",
    "    }\n",
    "    def __init__(self, kernel='polynomial', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        self.fit_intercept_ = False\n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        params['degree'] = kwargs.get('degree', d)\n",
    "        return params\n",
    "    def fit_K(self, K, y, **kwargs):\n",
    "        pass\n",
    "    def decision_function_K(self, K):\n",
    "        pass\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        K = self.kernel_function_(self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        return self.fit_K(K, y, **kwargs)\n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return self.decision_function_K(K_x)\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    def predict_K(self, K):\n",
    "        pass\n",
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, alpha=0.1, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "    def fit_K(self, K, y):\n",
    "        n = K.shape[0]\n",
    "        assert (n == len(y))\n",
    "        A = K + self.alpha*np.identity(n)\n",
    "        self.eta = np.linalg.solve(A , y)\n",
    "        return self\n",
    "    def decision_function_K(self, K_x):\n",
    "        return K_x.dot(self.eta)\n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)\n",
    "    def predict_K(self, K_x):\n",
    "        return self.decision_function_K(K_x)\n",
    "kernel = 'polynomial'\n",
    "kr_model = KernelRidgeRegression(\n",
    "    kernel=kernel,\n",
    "    alpha=grid_search.best_params_['alpha'],\n",
    "    )\n",
    "kr_model.fit(X_train, y_train)\n",
    "eta = kr_model.eta\n",
    "x1, x2, x3, x4, x5 = sp.symbols('x1 x2 x3 x4 x5') \n",
    "polynomial_kernel = (1 + x1*sp.Symbol('xi1') + x2*sp.Symbol('xi2') + x3*sp.Symbol('xi3') + x4*sp.Symbol('xi4') + x5*sp.Symbol('xi5'))**d\n",
    "f_beta = 0\n",
    "for i in range(len(X_train)):\n",
    "    f_beta += eta[i] * polynomial_kernel.subs({'xi1': X_train.iloc[i][0], 'xi2': X_train.iloc[i][1], 'xi3': X_train.iloc[i][2], 'xi4': X_train.iloc[i][3], 'xi5': X_train.iloc[i][4]})\n",
    "candidate_CL = sp.expand(f_beta)\n",
    "print(\"Candidate Conservation Law:\")\n",
    "sp.pprint(candidate_CL)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "coefficients = list(candidate_CL.as_coefficients_dict().values())\n",
    "terms = list(candidate_CL.as_coefficients_dict().keys())\n",
    "filtered_terms = [term for coeff, term in zip(coefficients, terms) if abs(coeff) > 0.0001]\n",
    "filtered_ex = sum(Mul(coeff, term) for coeff, term in zip(coefficients, terms) if term in filtered_terms)\n",
    "print(\"Final Conservation Law:\")\n",
    "sp.pprint(filtered_ex)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp1 = filtered_ex\n",
    "div1 = exp1\n",
    "simp_exp1 = simplify(div1)\n",
    "filtered_exp1 = sum(term for term in simp_exp1.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Candidate CL:\")\n",
    "sp.pprint(filtered_exp1)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp = filtered_ex\n",
    "tar = x5 * x3\n",
    "tar_coef = exp.coeff(tar)\n",
    "deno = tar_coef\n",
    "div = exp / deno\n",
    "simp_exp = simplify(div)\n",
    "filtered_exp = sum(term for term in simp_exp.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Simplified Candidate CL:\")\n",
    "sp.pprint(filtered_exp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "with open(\"../../../results/Lorenz_System/Lorenz_System_T5_40/candidate_CL.txt\", \"w\") as file:\n",
    "    file.write(str(candidate_CL))\n",
    "with open(\"../../../results/Lorenz_System/Lorenz_System_T5_40/candidate_CL.txt\", \"r\") as file:\n",
    "    candidate_CL = sp.sympify(file.read())\n",
    "df3 = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/holdoutp_data50.csv')\n",
    "traj_len = df3.groupby('trajectory').size()\n",
    "rep1 = int(round(traj_len.mean()))\n",
    "expression = sp.lambdify((x1, x2, x3, x4, x5), candidate_CL, \"numpy\")\n",
    "df3['lamhold'] = expression(df3['x1'], df3['x2'], df3['x3'], df3['x4'], df3['x5'])\n",
    "da = {'y{}'.format(i): h_value[i] for i in range(len(h_value))}\n",
    "df3['Coluh(lamhold)'] = [da[f'y{i}'] for i in range(m) for _ in range(rep1)]\n",
    "columns_to_compare = [('lamhold', 'Coluh(lamhold)')]\n",
    "for col1, col2 in columns_to_compare:\n",
    "    rmse = np.sqrt(mean_squared_error(df3[col1], df3[col2]))\n",
    "    print(f'Generalisation Error (RMSE): {rmse}')\n",
    "    print(\"\")\n",
    "with open(\"../../../results/Lorenz_System/Lorenz_System_T5_40/candidate_CL.txt\", \"r\") as file:\n",
    "    candidate_CL = sp.sympify(file.read())\n",
    "f = sp.lambdify((x1, x2, x3, x4, x5), candidate_CL, \"numpy\")\n",
    "dat = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/holdoutp_data50.csv')\n",
    "trajectories = dat['trajectory'].unique()\n",
    "total_sum_squared_normalized_functional_value = 0\n",
    "total_data_points = 0\n",
    "num_x_variables = 5\n",
    "for trajectory in trajectories:\n",
    "    trajectory_data = dat[dat['trajectory'] == trajectory].copy()  \n",
    "    cols = ['x' + str(i) for i in range(1, num_x_variables + 1)] # number of variable\n",
    "    trajectory_data['functional_value'] = f(*trajectory_data[cols].values.T)\n",
    "    mean_value = trajectory_data['functional_value'].mean()\n",
    "    trajectory_data['functional_value_minus_mean'] = trajectory_data['functional_value'] - mean_value\n",
    "    trajectory_data['normalized_functional_value'] = trajectory_data['functional_value_minus_mean'] / mean_value\n",
    "    trajectory_data['squared_normalized_functional_value'] = trajectory_data['normalized_functional_value'] ** 2\n",
    "    total_sum_squared_normalized_functional_value += trajectory_data['squared_normalized_functional_value'].sum()\n",
    "    total_data_points += len(trajectory_data)\n",
    "average_squared_normalized_functional_value = total_sum_squared_normalized_functional_value / total_data_points\n",
    "standard_deviation = math.sqrt(average_squared_normalized_functional_value)\n",
    "print(\" Relative deviation:\", standard_deviation)\n",
    "print(\"\")\n",
    "\n",
    "##### Second Search\n",
    "\n",
    "def solve_for_lambda(data, c, d, lambda_value):\n",
    "    B5d = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "    traj_len = B5d.groupby('trajectory').size()\n",
    "    rep = int(round(traj_len.mean()))\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I)\n",
    "    m = 5 # number of trajectory\n",
    "    num_y_variables = m\n",
    "    y_symbols = [sp.symbols(f'y{i}') for i in range(num_y_variables)]\n",
    "    y_pattern = [sp.symbols(f'y{i}') for i in range(m)]\n",
    "    y_repeated = np.repeat(y_pattern, rep, axis=0)\n",
    "    y = sp.Matrix([sp.symbols(f'y{i}') for i in range(m)])  \n",
    "    M_matrix = sp.Matrix(K_with_I_inv)\n",
    "    n = K.shape[0]\n",
    "    M = sp.zeros(n, m)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            start_idx = j * rep\n",
    "            end_idx = (j + 1) * rep\n",
    "            M[i, j] = sp.Add(*M_matrix[i, start_idx:end_idx])\n",
    "    M_transpose = M.transpose()\n",
    "    A = M \n",
    "    F =A.T\n",
    "    return A, K_with_I_inv, F\n",
    "data = np.loadtxt('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv', delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4))\n",
    "solutions_combined = []\n",
    "for i in range(7, 8):\n",
    "    lambda_value = 10**(-i)\n",
    "    A, K_with_I_inv, F = solve_for_lambda(data, c=1, d=2, lambda_value=lambda_value)\n",
    "def multilinear_coefficient(n, *ks):\n",
    "    numerator = math.factorial(n)\n",
    "    denominator = 1\n",
    "    for k in ks:\n",
    "        denominator *= math.factorial(k)\n",
    "    return numerator // denominator\n",
    "def multilinear_expansion(variables, n, row):\n",
    "    expansions = []\n",
    "    for ks in itertools.product(range(n + 1), repeat=len(variables)):\n",
    "        if sum(ks) == n:\n",
    "            coefficient = multilinear_coefficient(n, *ks)\n",
    "            values = [row[var] ** k if var != '1' else 1 for var, k in zip(variables, ks)]\n",
    "            term_value = coefficient * math.prod(values)\n",
    "            expansions.append(term_value)\n",
    "    return expansions[::-1]\n",
    "def multilinear_expansion1(variables1, n1):\n",
    "    expansions1 = []  \n",
    "    for ks in itertools.product(range(n1 + 1), repeat=len(variables1)):\n",
    "        if sum(ks) == n1:\n",
    "            terms1 = [f\"{var}**{k}\" if k != 0 else f\"{var}\" for var, k in zip(variables1, ks) if k != 0]\n",
    "            term1 = \" * \".join(terms1)\n",
    "            expansions1.append(term1)\n",
    "    return expansions1[::-1]\n",
    "def generate_inner_products(coefficients, terms):\n",
    "    inner_products = [f\"{c}*{t}\" for c, t in zip(coefficients, terms)]\n",
    "    return inner_products\n",
    "data = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "n = 2\n",
    "data['c'] = 1\n",
    "num_x_variables = 5\n",
    "variables = ['c'] + [f'x{i}' for i in range(1, num_x_variables + 1)]\n",
    "n1 = 2\n",
    "variables1 = ['1'] + [f'x{i}' for i in range(1, num_x_variables + 1)]\n",
    "all_entries = []\n",
    "for index, row in data.iterrows():\n",
    "    result = multilinear_expansion(variables, n, row)\n",
    "    result1 = multilinear_expansion1(variables1, n1)\n",
    "    expressions = generate_inner_products(result, result1)\n",
    "    all_entries.append(result)\n",
    "matrix = np.array(all_entries)\n",
    "def generate_symbolic_terms(degree=2):\n",
    "    terms = []\n",
    "    variables = [x1, x2, x3, x4, x5]\n",
    "    terms.append('1**1')\n",
    "    for d in range(1, degree + 1):\n",
    "        for comb in combinations_with_replacement(variables, d):\n",
    "            term = ' * '.join([f'{v}**{comb.count(v)}' for v in set(comb)])\n",
    "            terms.append(term)\n",
    "    return terms\n",
    "def print_as_single_row(terms):\n",
    "    matrix_row = \"  \".join(terms)\n",
    "    shape = (1, len(terms)) \n",
    "result = generate_symbolic_terms(degree=2)\n",
    "print_as_single_row(result)\n",
    "F_numpy = np.array(F.tolist()).astype(np.float64)\n",
    "if matrix.shape[1] == F_numpy.shape[0]:\n",
    "    result = np.dot(F_numpy, matrix)\n",
    "ds=np.dot(F_numpy, matrix)\n",
    "shape = print_as_single_row(result)\n",
    "symbolic_matrix = sp.Matrix(1, len(result), result)\n",
    "ds_symbolic = ds * symbolic_matrix.T \n",
    "shape = print_as_single_row(result)\n",
    "symbolic_matrix = sp.Matrix(1, len(result), result)\n",
    "ds_symbolic = ds * symbolic_matrix.T \n",
    "def compute_gradients(expr, variables):\n",
    "    return [sp.diff(expr, var) for var in variables]\n",
    "variables = [x1, x2, x3, x4, x5]\n",
    "gradient_rows = []\n",
    "for i in range(ds_symbolic.shape[0]):\n",
    "    gradient_row = compute_gradients(ds_symbolic[i, 0], variables)\n",
    "    gradient_rows.append(gradient_row)\n",
    "gradients_matrix = sp.Matrix(gradient_rows)\n",
    "N = 1\n",
    "D = num_x_variables\n",
    "lower_bound = -2\n",
    "upper_bound = 2\n",
    "points = np.random.uniform(lower_bound, upper_bound, (N, D))\n",
    "rp = ', '.join(f\"{x:.8f}\" for x in points[0])\n",
    "values = [float(x) for x in rp.split(', ')]\n",
    "x1_value, x2_value, x3_value, x4_value, x5_value = values\n",
    "P_J = gradients_matrix.subs({x1: x1_value, x2: x2_value, x3: x3_value, x4: x4_value, x5: x5_value})\n",
    "P_J_matrix = Matrix(P_J)\n",
    "rank_P_J = P_J_matrix.rank()\n",
    "f = filtered_exp1\n",
    "f_vector = sp.Matrix([f])\n",
    "variables = sp.Matrix([x1, x2, x3, x4, x5])\n",
    "grad_f1 = f_vector.jacobian(variables)\n",
    "sp.pprint(grad_f1)\n",
    "grad_f1_shape = grad_f1.shape\n",
    "x1_value, x2_value, x3_value, x4_value, x5_value = values\n",
    "P_J1 = grad_f1.subs({x1: x1_value, x2: x2_value, x3: x3_value, x4: x4_value, x5: x5_value})\n",
    "P_J_matrix1 = Matrix(P_J1) \n",
    "rank_P_J1 = P_J_matrix1.rank() \n",
    "dJ = P_J_matrix1 * P_J_matrix \n",
    "def solve_for_lambda(data, c, d, lambda_value):\n",
    "    B5d = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "    traj_len = B5d.groupby('trajectory').size()\n",
    "    rep = int(round(traj_len.mean()))\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I)\n",
    "    m = 5 # number of trajectory\n",
    "    num_y_variables = m\n",
    "    y_symbols = [sp.symbols(f'y{i}') for i in range(num_y_variables)]\n",
    "    y_pattern = [sp.symbols(f'y{i}') for i in range(m)]\n",
    "    y_repeated = np.repeat(y_pattern, rep, axis=0)\n",
    "    y = sp.Matrix([sp.symbols(f'y{i}') for i in range(m)])  \n",
    "    M_matrix = sp.Matrix(K_with_I_inv)\n",
    "    n = K.shape[0]\n",
    "    M = sp.zeros(n, m)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            start_idx = j * rep\n",
    "            end_idx = (j + 1) * rep\n",
    "            M[i, j] = sp.Add(*M_matrix[i, start_idx:end_idx])\n",
    "    M_transpose = M.transpose()\n",
    "    A = M \n",
    "    F =A.T\n",
    "    return A, K_with_I_inv, F\n",
    "data = np.loadtxt('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv', delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4))\n",
    "solutions_combined = []\n",
    "for i in range(7, 8):\n",
    "    lambda_value = 10**(-i)\n",
    "    A, K_with_I_inv, F = solve_for_lambda(data, c=1, d=2, lambda_value=lambda_value)\n",
    "a1 = np.random.uniform(-3, 3, num_x_variables)\n",
    "def solve_for_lambda(data, c, d, lambda_value):\n",
    "    B5d = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "    traj_len = B5d.groupby('trajectory').size()\n",
    "    rep = int(round(traj_len.mean()))\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I) \n",
    "    M_matrix = sp.Matrix(K_with_I_inv)\n",
    "    n = K.shape[0]\n",
    "    m = 5\n",
    "    M = sp.zeros(n, m)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            start_idx = j * rep\n",
    "            end_idx = (j + 1) * rep\n",
    "            M[i, j] = sp.Add(*M_matrix[i, start_idx:end_idx])\n",
    "    M_transpose = M.transpose()\n",
    "    A = M_transpose @ M\n",
    "    F =A\n",
    "    return A, K_with_I_inv, F\n",
    "data = np.loadtxt('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv', delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4))\n",
    "solutions_combined = []\n",
    "for i in range(7, 8):\n",
    "    lambda_value = 10**(-i)\n",
    "    A, K_with_I_inv, F = solve_for_lambda(data, c=1, d=2, lambda_value=lambda_value)\n",
    "def solve_for_lambda(data, c, d, lambda_value):\n",
    "    B5d = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv')\n",
    "    traj_len = B5d.groupby('trajectory').size()\n",
    "    rep = int(round(traj_len.mean()))\n",
    "    K = compute_kernel_matrix(data, c, d)\n",
    "    I = np.eye(K.shape[0])\n",
    "    K_with_I = K + lambda_value * I\n",
    "    K_with_I_inv = np.linalg.inv(K_with_I)\n",
    "    M_matrix = sp.Matrix(K_with_I_inv)\n",
    "    n = K.shape[0]\n",
    "    m = 5\n",
    "    M = sp.zeros(n, m)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            start_idx = j * rep\n",
    "            end_idx = (j + 1) * rep\n",
    "            M[i, j] = sp.Add(*M_matrix[i, start_idx:end_idx])\n",
    "    M_transpose = M.transpose()\n",
    "    A = M_transpose @ M\n",
    "    F = np.array(A.evalf()).astype(np.float64)\n",
    "    return A, K_with_I_inv, F\n",
    "N = 1\n",
    "D = num_x_variables \n",
    "lower_bound = -2\n",
    "upper_bound = 2\n",
    "points = np.random.uniform(lower_bound, upper_bound, (N, D))\n",
    "rp = ', '.join(f\"{x:.8f}\" for x in points[0])\n",
    "values = [float(x) for x in rp.split(', ')]\n",
    "x1_value, x2_value, x3_value, x4_value, x5_value = values\n",
    "P_J = gradients_matrix.subs({x1: x1_value, x2: x2_value, x3: x3_value, x4: x4_value, x5: x5_value})\n",
    "P_J_matrix = sp.Matrix(P_J)\n",
    "rank_P_J = P_J_matrix.rank()\n",
    "dJ = P_J_matrix1 * P_J_matrix\n",
    "data = np.loadtxt('../../../Data/Lorenz_System/Lorenz_System_T5_40/trainingp_data50.csv', delimiter=',', skiprows=1, usecols=(0, 1, 2, 3, 4))\n",
    "solutions_combined = []\n",
    "for i in range(7, 8):\n",
    "    lambda_value = 10**(-i)\n",
    "    A, K_with_I_inv, F = solve_for_lambda(data, c=1, d=2, lambda_value=lambda_value)\n",
    "    q = np.zeros(F.shape[0])\n",
    "    G = sparse.csc_matrix((0, F.shape[0]))\n",
    "    h = np.zeros(0)\n",
    "    a = np.array([values], dtype=np.float64)\n",
    "    dJ_numeric = np.array(dJ.evalf()).astype(np.float64)\n",
    "    r = np.array([dJ_numeric], dtype=np.float64)\n",
    "    F_sparse = sparse.csc_matrix(F)\n",
    "    A_eq = sparse.csc_matrix(np.vstack([a.reshape(1, -1), r.reshape(1, -1)]))\n",
    "    b_eq = np.array([1.0, 0.0], dtype=np.float64)\n",
    "    y = solve_qp(F_sparse, q, G, h, A_eq, b_eq, solver=\"clarabel\")\n",
    "symbolic_matrix = sp.Matrix(1, len(result), result)\n",
    "ds_symbolic = ds * symbolic_matrix.T \n",
    "y_values = np.array(y)\n",
    "y = sp.Matrix(y_values)\n",
    "pr = y.T * ds_symbolic\n",
    "pr_expr = pr[0] \n",
    "SCL = str(pr_expr)\n",
    "with open(\"../../../results/Lorenz_System/Lorenz_System_T5_40/SCL.txt\", \"w\") as file:\n",
    "    file.write(str(SCL))\n",
    "with open(\"../../../results/Lorenz_System/Lorenz_System_T5_40/SCL.txt\", \"r\") as file:\n",
    "    SCL = sp.sympify(file.read())\n",
    "f = sp.lambdify((x1, x2, x3, x4, x5), SCL, \"numpy\")\n",
    "dat = pd.read_csv('../../../Data/Lorenz_System/Lorenz_System_T5_40/holdoutp_data50.csv')\n",
    "trajectories = dat['trajectory'].unique()\n",
    "total_sum_squared_normalized_functional_value = 0\n",
    "total_data_points = 0\n",
    "num_x_variables = 5\n",
    "for trajectory in trajectories:\n",
    "    trajectory_data = dat[dat['trajectory'] == trajectory].copy()  \n",
    "    cols = ['x' + str(i) for i in range(1, num_x_variables + 1)] # number of variable\n",
    "    trajectory_data['functional_value'] = f(*trajectory_data[cols].values.T)\n",
    "    mean_value = trajectory_data['functional_value'].mean()\n",
    "    trajectory_data['functional_value_minus_mean'] = trajectory_data['functional_value'] - mean_value\n",
    "    trajectory_data['normalized_functional_value'] = trajectory_data['functional_value_minus_mean'] / mean_value\n",
    "    trajectory_data['squared_normalized_functional_value'] = trajectory_data['normalized_functional_value'] ** 2\n",
    "    total_sum_squared_normalized_functional_value += trajectory_data['squared_normalized_functional_value'].sum()\n",
    "    total_data_points += len(trajectory_data)\n",
    "average_squared_normalized_functional_value = total_sum_squared_normalized_functional_value / total_data_points\n",
    "standard_deviation = math.sqrt(average_squared_normalized_functional_value)\n",
    "print(\"Second CL:\")\n",
    "sp.pprint(SCL)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "coefficients = list(SCL.as_coefficients_dict().values())\n",
    "terms = list(SCL.as_coefficients_dict().keys())\n",
    "filtered_terms = [term for coeff, term in zip(coefficients, terms) if abs(coeff) > 0.0001]\n",
    "filtered_ex = sum(Mul(coeff, term) for coeff, term in zip(coefficients, terms) if term in filtered_terms)\n",
    "print(\"Final Conservation Law:\")\n",
    "sp.pprint(filtered_ex)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp2 = filtered_ex\n",
    "div2 = exp2\n",
    "simp_exp2 = simplify(div2)\n",
    "filtered_exp2 = sum(term for term in simp_exp2.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Candidate CL:\")\n",
    "sp.pprint(filtered_exp2)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp = filtered_ex\n",
    "tar = x5 * x3\n",
    "tar_coef = exp.coeff(tar)\n",
    "deno = tar_coef\n",
    "div = exp / deno\n",
    "simp_exp = simplify(div)\n",
    "filtered_exp = sum(term for term in simp_exp.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Simplified Candidate CL:\")\n",
    "sp.pprint(filtered_exp)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\" Relative deviation:\", standard_deviation)\n",
    "print(\"\")\n",
    "\n",
    "#### Sparsification\n",
    "\n",
    "\n",
    "exprp1 = filtered_exp1\n",
    "variables = sp.symbols('x1:%d' % (num_x_variables + 2))\n",
    "polynomialp1 = sp.Poly(exprp1, *variables)\n",
    "polynomialp1 = sp.Poly(exprp1, *variables)\n",
    "coefficientsp1 = polynomialp1.coeffs(order='grevlex')\n",
    "coeff_matrixp1 = sp.Matrix(coefficientsp1)\n",
    "coeff_matrixp1\n",
    "exprp2 = filtered_exp2\n",
    "polynomialp2 = sp.Poly(exprp2, *variables)\n",
    "coefficientsp2 = polynomialp2.coeffs(order='grevlex')\n",
    "coeff_matrixp2 = sp.Matrix(coefficientsp2)\n",
    "coeff_matrixp2\n",
    "exprp2 = filtered_exp1\n",
    "polynomialp2 = sp.Poly(exprp2, *variables)\n",
    "order = 'grevlex' \n",
    "coefficientsp2 = polynomialp2.coeffs(order=order)\n",
    "coeff_list = list(coefficientsp2)\n",
    "terms = polynomialp2.monoms(order=order)\n",
    "coefficients = polynomialp2.coeffs()\n",
    "terms_with_coeffs = {sp.Mul(*[s**e for s, e in zip([*variables], term)]): coeff\n",
    "                      for term, coeff in zip(terms, coefficients)}\n",
    "for term in terms:\n",
    "    term_expr = sp.Mul(*[s**e for s, e in zip([*variables], term)])\n",
    "    coeff = terms_with_coeffs.get(term_expr, 0)\n",
    "exprp1 = filtered_exp2\n",
    "polynomialp1 = sp.Poly(exprp1, *variables)\n",
    "order = 'grevlex' \n",
    "coefficientsp1 = polynomialp1.coeffs(order=order)\n",
    "coeff_list = list(coefficientsp1)\n",
    "terms = polynomialp1.monoms(order=order)\n",
    "coefficients = polynomialp1.coeffs()\n",
    "terms_with_coeffs = {sp.Mul(*[s**e for s, e in zip([*variables], term)]): coeff\n",
    "                      for term, coeff in zip(terms, coefficients)}\n",
    "for term in terms:\n",
    "    term_expr = sp.Mul(*[s**e for s, e in zip([*variables], term)])\n",
    "    coeff = terms_with_coeffs.get(term_expr, 0)\n",
    "terms = polynomialp2.monoms(order=order)\n",
    "coefficients = polynomialp2.coeffs()\n",
    "terms_with_coeffs = {sp.Mul(*[s**e for s, e in zip([*variables], term)]): coeff\n",
    "                      for term, coeff in zip(terms, coefficients)}\n",
    "formatted_terms = [str(sp.Mul(*[s**e for s, e in zip([*variables], term)])) for term in terms]\n",
    "formatted_terms_str = ', '.join(formatted_terms)\n",
    "vp1 = [sp.Mul(*[s**e for s, e in zip([*variables], term)]).evalf() for term in terms]\n",
    "if coeff_matrixp1.shape[0] != coeff_matrixp2.shape[0]:\n",
    "    raise ValueError(\"The two coefficient matrices do not have the same number of rows.\")\n",
    "combined_matrixp = sp.Matrix.hstack(coeff_matrixp1, coeff_matrixp2)\n",
    "combined_matrixp\n",
    "C = combined_matrixp\n",
    "a = cp.Variable(2)\n",
    "Ca = C @ a\n",
    "objective = cp.Minimize(cp.norm1(Ca))\n",
    "constraints = [\n",
    "    cp.sum(a) == 1\n",
    "]\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve()\n",
    "a_optimal = a.value\n",
    "C = combined_matrixp\n",
    "a = np.array(a_optimal)\n",
    "resultp = np.dot(C, a)\n",
    "formatted_resultp = ', '.join(map(str, resultp))\n",
    "v3_str = '[' + ', '.join(f'{x:.15g}' for x in resultp) + ']'\n",
    "v3_list = ast.literal_eval(v3_str)\n",
    "v3_sympy = [sp.Float(x) for x in v3_list]\n",
    "v1 = [sp.Mul(*[s**e for s, e in zip([*variables], term)]).evalf() for term in terms]\n",
    "dot_product1 = sum(sp.Mul(v1_i, v3_i) for v1_i, v3_i in zip(v1, v3_sympy))\n",
    "dot_product1_simplified = sp.simplify(dot_product1)\n",
    "print(\"First sparse CL:\")\n",
    "sp.pprint(dot_product1_simplified)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "threshold = 0.0001\n",
    "filtered_terms = []\n",
    "for term in dot_product1_simplified.as_ordered_terms():\n",
    "    coeff = term.as_coeff_Mul()[0] \n",
    "    if abs(coeff) > threshold:\n",
    "        filtered_terms.append(term)\n",
    "filtered_expression = sum(filtered_terms)\n",
    "print(\"Simplified First sparse CL:\")\n",
    "sp.pprint(filtered_expression)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp3 = filtered_expression\n",
    "tar3 = x4 * x3\n",
    "tar_coef3 = exp3.coeff(tar3)\n",
    "deno3 = tar_coef3\n",
    "div3 = exp3 / deno3\n",
    "simp_exp3 = simplify(div3)\n",
    "filtered_exp3 = sum(term for term in simp_exp3.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Final First Sparse CL:\")\n",
    "sp.pprint(filtered_exp3)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "if coeff_matrixp1.shape[0] != coeff_matrixp2.shape[0]:\n",
    "    raise ValueError(\"The two coefficient matrices do not have the same number of rows.\")\n",
    "combined_matrixp = sp.Matrix.hstack(coeff_matrixp1, coeff_matrixp2)\n",
    "C = np.array(combined_matrixp).astype(np.float64)\n",
    "a = np.array(a_optimal)\n",
    "resultp = np.dot(C, a)\n",
    "final_result = np.dot(resultp, C)\n",
    "C = combined_matrixp\n",
    "a = cp.Variable(2)\n",
    "Ca = C @ a\n",
    "objective = cp.Minimize(cp.norm1(Ca))\n",
    "constraints = [\n",
    "    cp.sum(a) == 1,\n",
    "    final_result[1] * a[1] + final_result[0] * a[0] == 0  # New constraint\n",
    "]\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve()\n",
    "a_optimal1 = a.value\n",
    "C = combined_matrixp\n",
    "a = np.array(a_optimal1)\n",
    "resultp = np.dot(C, a)\n",
    "formatted_resultp = ', '.join(map(str, resultp))\n",
    "v3_str = '[' + ', '.join(f'{x:.15g}' for x in resultp) + ']'\n",
    "v3_list = ast.literal_eval(v3_str)\n",
    "v3_sympy = [sp.Float(x) for x in v3_list]\n",
    "v1 = [sp.Mul(*[s**e for s, e in zip([*variables], term)]).evalf() for term in terms]\n",
    "dot_product1 = sum(sp.Mul(v1_i, v3_i) for v1_i, v3_i in zip(v1, v3_sympy))\n",
    "dot_product1_simplified = sp.simplify(dot_product1)\n",
    "v3_str = '[' + ', '.join(f'{x:.15g}' for x in resultp) + ']'\n",
    "v3_list = ast.literal_eval(v3_str)\n",
    "v3_sympy = [sp.Float(x) for x in v3_list]\n",
    "v1 = [sp.Mul(*[s**e for s, e in zip([*variables], term)]).evalf() for term in terms]\n",
    "dot_product1 = sum(sp.Mul(v1_i, v3_i) for v1_i, v3_i in zip(v1, v3_sympy))\n",
    "dot_product1_simplified = sp.simplify(dot_product1)\n",
    "threshold = 0.0001\n",
    "filtered_terms = []\n",
    "for term in dot_product1_simplified.as_ordered_terms():\n",
    "    coeff = term.as_coeff_Mul()[0] \n",
    "    if abs(coeff) > threshold:\n",
    "        filtered_terms.append(term)\n",
    "filtered_expression4 = sum(filtered_terms)\n",
    "print(\"Second CL:\")\n",
    "sp.pprint(dot_product1_simplified)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Simplified second CL:\")\n",
    "sp.pprint(filtered_expression4)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "exp4 = filtered_expression4\n",
    "tar4 = x3 * x5\n",
    "tar_coef4 = exp4.coeff(tar4)\n",
    "deno4 = tar_coef4\n",
    "div4 = exp4 / deno4\n",
    "simp_exp4 = simplify(div4)\n",
    "filtered_exp4 = sum(term for term in simp_exp4.args if term.has(x1) or term.has(x2) or term.has(x3))\n",
    "print(\"Final Second Sparse CL:\")\n",
    "sp.pprint(filtered_exp4)\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ef966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
